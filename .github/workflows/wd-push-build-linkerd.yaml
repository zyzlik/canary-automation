name: "[PUSH, WD] Build and Deploy Linkerd"

on:
  # push:
  #   branches: [ "main" ]
  workflow_dispatch:

jobs:
  build:
    runs-on: [ubuntu-latest]

    steps:
      - uses: actions/checkout@v3

      - name: docker build
        run: |
          docker build . -t zyzlik/canary-automation:latest
      
      - name: login to Docker Hub
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      
      - name: push
        run: |
          docker push zyzlik/canary-automation:latest
  deploy-stage-1:
    runs-on: [ubuntu-latest]
    needs: [build]
    steps:
      - uses: actions/checkout@v3
      - name: configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          aws-region: us-east-2
      - name: get hostname
        id: hostname
        run: |
          aws eks update-kubeconfig --name canary-automation
          kubectl config set-context arn:aws:eks:us-east-2:801176112578:cluster/canary-automation
          echo "::set-output name=hostname::$(kubectl get svc envoy -n projectcontour -o jsonpath='{.status.loadBalancer.ingress[].hostname}')"
      - name: deploy canary
        run: |
          aws eks update-kubeconfig --name canary-automation
          kubectl config set-context arn:aws:eks:us-east-2:801176112578:cluster/canary-automation
         
          # Deploy canary app with 5% traffic
          helm upgrade --install --create-namespace \
          --cleanup-on-fail --atomic -n canary-automation \
          --set stable_weight=90 --set canary_weight=5 \
          --set track=canary canary-automation-canary ./kubernetes-linkerd

      # - name: deploy baseline
      #   run: |
      #     # Deploy baseline
      #     helm upgrade --install --create-namespace \
      #     --cleanup-on-fail --atomic -n canary-automation \
      #     --set track=baseline --set ingress=false \
      #     canary-automation-baseline ./kubernetes 
  
      - name: analyze
        id: analyze-stage-1
        continue-on-error: true
        run: |
          # Wait for some traffic 
          sleep 30

          # Get Prometheus URL
          prometheus=$(kubectl get svc prometheus -n projectcontour-monitoring -o jsonpath='{.status.loadBalancer.ingress[].hostname}')

          # Get metrics
          baseline=$((curl "${prometheus}:9090/api/v1/query?query=rate(flask_http_request_duration_seconds_sum\{track=\"baseline\"\}\[5m\])/rate(flask_http_request_duration_seconds_count\{track=\"baseline\"\}\[5m\])") | jq '.["data"]["result"][1]["value"][0]')
          canary=$((curl "${prometheus}:9090/api/v1/query?query=rate(flask_http_request_duration_seconds_sum\{track=\"canary\"\}\[5m\])/rate(flask_http_request_duration_seconds_count\{track=\"canary\"\}\[5m\])') | jq '.["data"]["result"][1]["value"][0]')

          # Compare metrics
          # If canary latency is worse than baseline, exit and rollback
          if [[ "$canary" -gt "$baseline" ]]; then
            echo "::set-output name=result::failure"
            exit 1
          fi
      - name: rollback
        if: ${{ contains(steps.analyze-stage-1.result, 'failure') }}
        run: |
          # Delete canary
          helm delete canary-automation-canary -n canary-automation

          # Delete baseline
          # helm delete canary-automation-baseline -n canary-automation
  deploy-stage-2:
    runs-on: [ubuntu-latest]
    needs: [build, deploy-stage-1]
    if: ${{ contains(needs.deploy-stage-1.result, 'success' }}
    steps:
      - uses: actions/checkout@v3
      - name: configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          aws-region: us-east-2
      - name: get hostname
        id: hostname
        run: |
          aws eks update-kubeconfig --name canary-automation
          kubectl config set-context arn:aws:eks:us-east-2:801176112578:cluster/canary-automation
          echo "::set-output name=hostname::$(kubectl get svc envoy -n projectcontour -o jsonpath='{.status.loadBalancer.ingress[].hostname}')"
      - name: increase % canary
        run: |
          # Increase % of canary and baseline
          helm upgrade --install --create-namespace \
          --cleanup-on-fail --atomic -n canary-automation \
          --set stable_weight=90 --set canary_weight=10 \
          --set track=canary canary-automation-canary ./kubernetes-linkerd

      - name: analyze
        id: analyze-stage-2
        continue-on-error: true
        run: |
          # Wait for some traffic 
          sleep 30

          # Get Prometheus URL
          prometheus=$(kubectl get svc prometheus -n projectcontour-monitoring -o jsonpath='{.status.loadBalancer.ingress[].hostname}')

          # Get metrics
          baseline=$((curl "${prometheus}:9090/api/v1/query?query=rate(flask_http_request_duration_seconds_sum\{track=\"baseline\"\}\[5m\])/rate(flask_http_request_duration_seconds_count\{track=\"baseline\"\}\[5m\])") | jq '.["data"]["result"][1]["value"][0]')
          canary=$((curl "${prometheus}:9090/api/v1/query?query=rate(flask_http_request_duration_seconds_sum\{track=\"canary\"\}\[5m\])/rate(flask_http_request_duration_seconds_count\{track=\"canary\"\}\[5m\])') | jq '.["data"]["result"][1]["value"][0]')

          # Compare metrics
          # If canary latency is worse than baseline, exit and rollback
          if [[ "$canary" -gt "$baseline" ]]; then
            echo "::set-output name=result::failure"
            exit 1
          fi
      - name: rollback
        if: ${{ contains(steps.analyze-stage-2.result, 'failure') }}
        run: |
          # Delete canary
          helm delete canary-automation-canary -n canary-automation

          # Delete baseline
          # helm delete canary-automation-baseline -n canary-automation
  promote:
    runs-on: [ubuntu-latest]
    needs: [build, deploy-stage-1, deploy-stage-2]
    if: ${{ contains(needs.deploy-stage-1.result, 'success' && contains(needs.deploy-stage-2.result, 'success' }}
    steps:
      - uses: actions/checkout@v3
      - name: configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_KEY }}
          aws-region: us-east-2
      - name: get hostname
        id: hostname
        run: |
          aws eks update-kubeconfig --name canary-automation
          kubectl config set-context arn:aws:eks:us-east-2:801176112578:cluster/canary-automation
          echo "::set-output name=hostname::$(kubectl get svc envoy -n projectcontour -o jsonpath='{.status.loadBalancer.ingress[].hostname}')"
      - name: promote
        run: |
          # Deploy canary as stable
          helm upgrade --install --create-namespace \
          --cleanup-on-fail --atomic -n canary-automation \
          --set track=stable canary-automation-stable ./kubernetes-linkerd

          # Delete canary
          helm delete canary-automation-canary -n canary-automation

          # Delete baseline
          # helm delete canary-automation-baseline -n canary-automation
